** Introduction
# Précise le statut scientifique du travail (projet de recherche, ancrage institutionnel, etc.)

# Présenter le contexte normatif croissant dans la construction.

# Problématique : la difficulté d’accès et de quantification de la charge normative, les impacts potentiels de l'ampleur et la difficulté d'en connaitre

# Objectif : quantifier, caractériser et comparer la norme dans la construction.

** Périmètre de l'étude
L’étude se concentre sur les normes volontaires françaises (NF) référencées par AFNOR et publiées à la date de la collecte.
Le périmètre inclut toutes les normes relevant du domaine “Construction et urbanisme” selon la classification AFNOR Norm’Info.

Les normes ISO/IEC sont souvent transposées en normes NF (NF EN ISO, etc.)

AFNOR est le point d’entrée national reconnu par l’État pour la normalisation volontaire.

Les normes d’application obligatoire sont issues de ce corpus (via réglementations).

Par l'analyse des textes et de leurs métadonnées, nous tenterons de répondre aux questions suivantes :

Q1 : Quelle est l’ampleur documentaire du corpus normatif applicable à l’industrie de la construction, mesurée en nombre de documents et en volume paginé ?
Q2 : La filière construction présente-t-elle une densité normative supérieure à celle d’autres secteurs industriels comparables, en termes de nombre de normes actives et de leur volumétrie documentaire ?
Q3 : Comment les textes normatifs se répartissent-ils entre les sous-domaines techniques, professions et spécialités représentatives de la filière construction, selon les descripteurs et indices de classement ?


** Méthodologie
*** Cadre juridique
Il n'existe pas de base de données publiques recenssant l'ensemble des textes de normes et leurs métadonnées. Il convient donc de constituer cette base de donnée en collectant les informations publiquement accessibles.

Cette opération implique l'emplois du webscraping.

#+BEGIN_QUOTE
Le webscraping consiste à extraire automatiquement (to scrape : gratter), de manière massive des données d'un site web. -- INRAE[cite:@quesnevilleRecommandationsUsagesWebscraping2024]
#+END_QUOTE

La légalité d'une telle opération semble parfois faire débat. (ref à ajouter)

En droit français, le Code de la propriété intellectuelle précise les modalités de copie et de reproduction des bases de données :
#+BEGIN_QUOTE
Lorsqu'une base de données est mise à la disposition du public par le titulaire des droits, celui-ci ne peut interdire :

[...]

6° Les extractions, copies ou reproductions numériques d'une base de données, en vue de la fouille de textes et de données réalisée dans les conditions prévues à l'article L. 122-5-3. Pour l'application de cet article, les auteurs et titulaires des droits d'auteur s'entendent des producteurs de bases de données et les copies ou reproductions numériques d'œuvres s'entendent des extractions, copies ou reproductions numériques de bases de données ;

-- Article L342-3[cite:@CodeProprieteIntellectuelle]
#+END_QUOTE

Ce code précise également les droits de manipulation des textes dans un cadre de recherche :
#+BEGIN_QUOTE
Lorsque l'oeuvre a été divulguée, l'auteur ne peut interdire :

[...]

10° Les copies ou reproductions numériques d'une œuvre en vue de la fouille de textes et de données réalisée dans les conditions prévues à l'article L. 122-5-3 ;

-- Article L122-5[cite:@CodeProprieteIntellectuelle]
#+END_QUOTE

Et :
#+BEGIN_QUOTE
I.-On entend par fouille de textes et de données, au sens du 10° de l'article L. 122-5, la mise en œuvre d'une technique d'analyse automatisée de textes et données sous forme numérique afin d'en dégager des informations, notamment des constantes, des tendances et des corrélations.

II.-Des copies ou reproductions numériques d'œuvres auxquelles il a été accédé de manière licite peuvent être réalisées sans autorisation des auteurs en vue de fouilles de textes et de données menées à bien aux seules fins de la recherche scientifique par les organismes de recherche, les bibliothèques accessibles au public, les musées, les services d'archives ou les institutions dépositaires du patrimoine cinématographique, audiovisuel ou sonore, ou pour leur compte et à leur demande par d'autres personnes, y compris dans le cadre d'un partenariat sans but lucratif avec des acteurs privés.

[...]

Les copies et reproductions numériques effectuées lors d'une fouille de textes et de données sont stockées avec un niveau de sécurité approprié et peuvent être conservées à des fins exclusives de recherche scientifique, y compris pour la vérification des résultats de la recherche.

-- Article L122-5-3[cite:@CodeProprieteIntellectuelle]
#+END_QUOTE

*** Données collectées
Métadonnées accessibles publiquement via Norm’Info et Boutique AFNOR :
    Référence (ex : NF C15-100)
    Titre
    Date de publication
    Nombre de pages
    Codes ICS
    Indice de classement
    Domaine technique
    Commission de normalisation
# Prévois un tableau synthétique des métadonnées collectées pour la transparence méthodologique

*** Protocole technique
Méthode de collecte : Web scraping (à documenter)

Langage : Python 3

Stockage : Fichier CSV encodé UTF-8

Limite : seules les normes publiées, disponibles à la vente ou référencées, sont incluses.

#+CAPTION: Code de collecte des informations
#+NAME: fig:afnor.py
#+ATTR_LATEX: :placement [htbp]
#+BEGIN_SRC python :results verbatim
import requests, csv, time
from bs4 import BeautifulSoup

base_url = "https://norminfo.afnor.org/search?typeResult=normes-publiees&cosID=348&domainID=11581"
headers = {"User-Agent": "Mozilla/5.0"}

def safe_select_text(soup, selector):
    el = soup.select_one(selector)
    return el.get_text(strip=True) if el else ""

def get_page_url(page_num):
    # The site uses ?page= for pagination
    return f"{base_url}&page={page_num}"

with open('normes_construction.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['Reference','Titre','Date_pub','Pages','Codes_ICS','Indice_classement'])
    page_num = 1
    total_scraped = 0
    while True:
        print(f"Scraping page {page_num}...")
        res = requests.get(get_page_url(page_num), headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        rows = soup.select('tbody tr')
        if not rows:
            print("No more rows found, stopping.")
            break
        for row in rows:
            try:
                ref = safe_select_text(row, 'td:nth-of-type(2)')
                titre = safe_select_text(row, 'td:nth-of-type(1)')
                if not ref:
                    continue
                search_url = f"https://www.boutique.afnor.org/fr-fr/resultats?Keywords={ref.replace(' ','%20')}&StandardStateIds=1"
                res2 = requests.get(search_url, headers=headers)
                soup2 = BeautifulSoup(res2.text, 'html.parser')
                link = soup2.select_one('.products div.product-title a')
                if not link:
                    continue
                norme_url = "https://www.boutique.afnor.org" + link['href']
                res3 = requests.get(norme_url, headers=headers)
                soup3 = BeautifulSoup(res3.text, 'html.parser')
                date_pub = safe_select_text(soup3, '#label-control-date-parution + .value')
                pages = safe_select_text(soup3, '#label-control-nb-pages + .value')
                ics_list = [item.get_text(strip=True) for item in soup3.select('#label-control-codesICS + .value li')]
                ics = ", ".join(ics_list)
                indice = safe_select_text(soup3, '#label-control-indice + .value')
                writer.writerow([ref, titre, date_pub, pages, ics, indice])
                total_scraped += 1
                time.sleep(1)  # Be polite to the server
            except Exception as e:
                print(f"Error processing {ref}: {e}")
        page_num += 1
    print(f"Total entries scraped: {total_scraped}")
#+END_SRC

** Méthodes d'analyse
    Analyse descriptive :
        Nombre total de documents / pages
        Évolution temporelle des publications (si date disponible)

    Analyse comparative :
        Densité normative dans la construction vs autres domaines AFNOR (en comparant les volumes ICS sectoriels)

    Analyse thématique / taxonomique :
        Catégorisation des normes par code ICS, indice de classement, domaine technique
        Projection possible par métier : architecture, génie civil, thermique, électricité…

Outils recommandés : Python (pandas + matplotlib)

** Résultats obtenus
Cartographie de la norme dans la construction
# Vis : Graphe, Timeline

Poids normatif par spécialité
# Vis : diagramme de barre,

Identification d’une sur-normativité éventuelle

Premiers indicateurs pour évaluer la « charge de la norme »
# Vis : Quantification des pages par documents et par périmètres : diagramme de boite à moustache ou violon

** Discussion et perspectives


